{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving an Existing Image Classifier (Fine Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In my previous notebook, `01 - CNN based image classification.ipynb`, I started learning about `Image Classification using the Supervised Learning` and how it can assist me categorizing images. The image classification model classifies images into two categories:\n",
    "\n",
    "- `Illustration`: Images that do not contain any accompanying text or dialogue.\n",
    "- `Manga`: Images that do contain text or dialogue.\n",
    "\n",
    "Instead of starting from scratch, my aim is to enhance the performance of the existing image classifier model. \n",
    "My objective remains unchanged: to classify images into the `Illustration` and `Manga` categories. \n",
    "However, I will employ `fine-tuning` technique to improve the classifier model. \n",
    "The existing model will be tuned using a larger image dataset, so it becomes more expert at distinguishing between `Illustration` and `Manga` images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom library module\n",
    "from model.ImportModel import ImportModel\n",
    "from module.DatasetProcessor import DatasetProcessor\n",
    "from script.plot_training_history import plot_training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"dataset_dir\": \".\\DATASET\\ILLUST VS MANGA\", # Dataset directory path\n",
    "    \"h5\": \".\\export model\\Res2Net50SE_224x224_2Class (ILLUST VS MANGA).h5\",\n",
    "    \"batch\": 8, # Batch size\n",
    "    \"optimizer\": tf.keras.optimizers.Adam(learning_rate=1e-6, decay=1e-4), # Set very low learning rate for whole fine tuning model\n",
    "    \"loss_func\": tf.losses.CategoricalCrossentropy(), # Loss function (Categorical Cross-Entropy)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid out of memory errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare functions\n",
    "- `Custom_ImageDataGenerator`\n",
    "- `raw_data_processing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Custom_ImageDataGenerator(image_path, label, image_size):\n",
    "    # Read the image file from the given path\n",
    "    image = tf.io.read_file(image_path)\n",
    "    \n",
    "    # Decode the image into a tensor, disabling animation expansion\n",
    "    image = tf.image.decode_image(image, expand_animations=False)\n",
    "    \n",
    "    # Resize the image to the specified dimensions while preserving aspect ratio and using antialiasing\n",
    "    image = tf.image.resize(image, (image_size, image_size),\n",
    "                            preserve_aspect_ratio=True,\n",
    "                            antialias=True)\n",
    "    \n",
    "    # Resize the image with padding to ensure it has the exact dimensions specified\n",
    "    image = tf.image.resize_with_pad(image, image_size, image_size)\n",
    "    \n",
    "    # Normalize the image pixel values to the range [0, 1] by dividing by 255.0\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_processing(data_list, dict_class, image_size):\n",
    "    # Extract the image file paths from the data_list\n",
    "    path_list = [path for path, _ in data_list]\n",
    "    \n",
    "    # Map class labels to their corresponding dictionary values\n",
    "    label_list = [dict_class[label] for _, label in data_list]\n",
    "    \n",
    "    # Create a list of image size values to be used as a constant size in the dataset\n",
    "    size_list = [image_size] * len(label_list)\n",
    "    \n",
    "    # Create a TensorFlow dataset from the extracted lists\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((path_list, label_list, size_list))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImportModel(CFG[\"h5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples, where each tuple contains the image path and its class label\n",
    "path_list = [os.path.join(root,image) for root, _, files in os.walk(CFG[\"dataset_dir\"], topdown=True) for image in files]\n",
    "path_list = [(path, path.split('\\\\')[-2]) for path in path_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call custom class module\n",
    "processor = DatasetProcessor(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare class list and its corresponding dictionary for class-label mapping\n",
    "processor.create_class_dict(mode=\"onehot\")\n",
    "\n",
    "processor.class_list, processor.class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing datasets\n",
    "processor.train_test_splitter(test_ratio=10)\n",
    "\n",
    "len(processor.train_data), len(processor.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset\n",
    "train_dataset = raw_data_processing(processor.train_data, processor.class_dict, model.image_size)\n",
    "train_dataset = train_dataset.map(Custom_ImageDataGenerator)\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_dataset))\n",
    "train_dataset = train_dataset.batch(batch_size=CFG[\"batch\"], drop_remainder = True)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Prepare the testing dataset\n",
    "test_dataset = raw_data_processing(processor.test_data, processor.class_dict, model.image_size)\n",
    "test_dataset = test_dataset.map(Custom_ImageDataGenerator)\n",
    "test_dataset = test_dataset.batch(batch_size=CFG[\"batch\"], drop_remainder = False)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Early Stopping callback that monitors validation loss and stops training if it doesn't improve significantly\n",
    "EarlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                     min_delta=0.01, \n",
    "                                                     patience=20, \n",
    "                                                     restore_best_weights=True, \n",
    "                                                     verbose=1)\n",
    "\n",
    "# Compile the model with the specified optimizer and loss function\n",
    "model.compile(optimizer=CFG[\"optimizer\"], loss=CFG[\"loss_func\"])\n",
    "\n",
    "# Train the model on the training dataset with early stopping and a maximum of 100 epochs\n",
    "model.train(train_dataset, test_dataset, epochs=1000, callbacks=[EarlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation by plotting history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model.model.name + \"_fine_tune\"\n",
    "model.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
